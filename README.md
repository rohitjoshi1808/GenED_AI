# ğŸ“š Topic-based AI Question Generator & Evaluator

### ğŸ“– Overview
This project is an **AI-powered learning assistant** built with **Streamlit** and **OpenAI GPT** models.  
It allows users to:
- **Generate** creative, diverse, and difficulty-graded questions for any given topic or word.
- **Evaluate** their answers and get AI-based scoring and feedback.

The goal is to make topic-based self-assessment quick, engaging, and interactive for **students**, **teachers**, and **self-learners**.

---

### âœ¨ Features
- **AI Question Generation**: Creates **10 diverse questions** ranging from easy to hard for a given topic.
- **AI Answer Evaluation**: Scores answers out of 100, showing correct and incorrect questions.
- **Download Support**: Export generated questions as `.txt`.
- **Interactive UI**: Two-tab interface using **Streamlit**.
- **Configurable Model**: Easily switch between `gpt-4` and `gpt-3.5-turbo`.

---

## âš™ï¸ Installation
```
1ï¸âƒ£ Clone the Repository
bash
git clone https://github.com/your-username/ai-question-evaluator.git
cd ai-question-evaluator
2ï¸âƒ£ Create & Activate a Virtual Environment
bash
Copy
Edit
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
3ï¸âƒ£ Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
```

### ğŸ”§ Setup

1ï¸âƒ£ Add Your OpenAI API Key
Create a .env file in the project root:
env
Copy
Edit
OPENAI_API_KEY=your_openai_api_key_here

2ï¸âƒ£ Run the App
bash
Copy
Edit
streamlit run main.py

### ğŸ–¥ Usage

Tab 1: Question Generator
Enter a topic or word (e.g., "Artificial Intelligence").

Click Enter to get 10 AI-generated questions.

Download questions if needed.

Tab 2: Evaluator
Paste your answers to the generated questions.

Click Submit to get:

Total Score (out of 100)

Correct Questions

Incorrect Questions

### âš™ï¸ Configuration

You can adjust settings inside the app.py and evaluate.py:

Model: Change "gpt-4" to "gpt-3.5-turbo" for faster/cheaper results.

Temperature: Adjust creativity (0.0 = more factual, 1.0 = more creative).

Max Tokens: Control the output size.

### ğŸ— Architecture
```
bash
Copy
Edit
ğŸ“‚ ai-question-evaluator
â”‚
â”œâ”€â”€ app.py            # Question generator logic using OpenAI API
â”œâ”€â”€ evaluate.py       # Answer evaluation logic
â”œâ”€â”€ main.py           # Streamlit UI with two tabs
â”œâ”€â”€ .env              # API key storage (ignored in Git)
â”œâ”€â”€ requirements.txt  # Dependencies
â””â”€â”€ README.md         # Documentation
```
Flow:

User inputs topic â¡ app.py calls OpenAI â¡ Generates questions.

User inputs answers â¡ evaluate.py calls OpenAI â¡ Scores and feedback.

Results displayed in Streamlit interface.

### ğŸ”’ Safety & Disclaimer

AI Limitations: The evaluation is subjective and based on AI interpretation, which may not always be accurate.

Not a Replacement for Teachers: Use this as a study aid, not a grading system for official assessments.

Data Privacy: No answers are stored â€” only processed in real-time.

API Costs: Each request to OpenAI consumes API credits. Use wisely.

### ğŸš€ Future Enhancements

âœ… Multiple-choice question generation.

âœ… Leaderboard system for competitive quizzes.

âœ… User authentication & answer history tracking.

âœ… PDF export of questions & results.

âœ… Multi-topic quiz creation in one session.

âœ… Offline mode with locally stored Q&A sets.
